{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "505c8732-a866-44ac-b4bf-f8b8c6068555",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import DoubleQLearner, ModelHyperParams, PolicyGradient, QLearner, QLearnerWithTargetNetwork\n",
    "from environment_handler import CartPoleHandler\n",
    "from scripts import train, TrainingHyperParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2340129e-7cec-41bf-964b-f3dac115d15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 1ms/step - loss: 0.6505\n",
      "Current Benchmark Result:  25.0 Previously:  None . Saving weights...\n",
      "eps:  0.35\n",
      "Flushing buffer...\n",
      "50/50 [==============================] - 0s 915us/step - loss: 0.6360\n",
      "Current Benchmark Result:  40.5 Previously:  25.0 . Saving weights...\n",
      "eps:  0.245\n",
      "Flushing buffer...\n",
      "50/50 [==============================] - 0s 953us/step - loss: 0.6328\n",
      "Current Benchmark Result:  30.5 Previously:  40.5 . Collecting more data...\n",
      "100/100 [==============================] - 0s 986us/step - loss: 0.6328\n",
      "Current Benchmark Result:  15.0 Previously:  40.5 . Collecting more data...\n",
      "150/150 [==============================] - 0s 877us/step - loss: 0.6324\n",
      "Current Benchmark Result:  17.5 Previously:  40.5 . Collecting more data...\n",
      "200/200 [==============================] - 0s 864us/step - loss: 0.6325\n",
      "Current Benchmark Result:  9.0 Previously:  40.5 . Collecting more data...\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.6328\n",
      "300/300 [==============================] - 0s 875us/step - loss: 0.6328\n",
      "Current Benchmark Result:  10.0 Previously:  40.5 . Collecting more data...\n",
      "350/350 [==============================] - 0s 845us/step - loss: 0.6327\n",
      "Current Benchmark Result:  9.5 Previously:  40.5 . Collecting more data...\n",
      "400/400 [==============================] - 0s 884us/step - loss: 0.6328\n",
      "Current Benchmark Result:  18.0 Previously:  40.5 . Collecting more data...\n",
      "450/450 [==============================] - 0s 904us/step - loss: 0.6332\n",
      "Current Benchmark Result:  24.0 Previously:  40.5 . Collecting more data...\n",
      "500/500 [==============================] - 0s 851us/step - loss: 0.6327\n",
      "Current Benchmark Result:  10.0 Previously:  40.5 . Collecting more data...\n",
      "500/500 [==============================] - 0s 846us/step - loss: 0.6330\n",
      "Current Benchmark Result:  13.0 Previously:  40.5 . Collecting more data...\n",
      "500/500 [==============================] - 0s 829us/step - loss: 0.6328\n",
      "Current Benchmark Result:  10.0 Previously:  40.5 . Collecting more data...\n",
      "500/500 [==============================] - 0s 894us/step - loss: 0.6330\n",
      "Current Benchmark Result:  13.0 Previously:  40.5 . Collecting more data...\n",
      "500/500 [==============================] - 0s 848us/step - loss: 0.6328\n",
      "Current Benchmark Result:  23.0 Previously:  40.5 . Collecting more data...\n",
      "500/500 [==============================] - 0s 849us/step - loss: 0.6330\n",
      "Current Benchmark Result:  12.0 Previously:  40.5 . Collecting more data...\n",
      "500/500 [==============================] - 0s 839us/step - loss: 0.6328\n",
      "Current Benchmark Result:  9.0 Previously:  40.5 . Collecting more data...\n",
      "500/500 [==============================] - 0s 860us/step - loss: 0.6323\n",
      "Current Benchmark Result:  58.5 Previously:  40.5 . Saving weights...\n",
      "eps:  0.1715\n",
      "Flushing buffer...\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.6330\n",
      "Current Benchmark Result:  33.5 Previously:  58.5 . Collecting more data...\n",
      "100/100 [==============================] - 0s 891us/step - loss: 0.6332\n",
      "Current Benchmark Result:  10.0 Previously:  58.5 . Collecting more data...\n",
      "150/150 [==============================] - 0s 875us/step - loss: 0.6334\n",
      "Agent trained. Yay!\n"
     ]
    }
   ],
   "source": [
    "model_params = ModelHyperParams(\n",
    "    initial_epsilon=0.5,\n",
    "    epsilon_decay_constant=0.7,\n",
    "    no_hidden_layers=2,\n",
    "    units_per_hidden_layer=24,\n",
    "    optimizer=\"adam\",\n",
    "    kernel_initializer=\"he_uniform\"\n",
    ")\n",
    "training_params = TrainingHyperParams(\n",
    "    batch_size=2048,\n",
    "    epochs=1000,\n",
    "    steps_per_epoch=100*1024,\n",
    "    max_buffer_size=10*100*1024\n",
    ")\n",
    "\n",
    "env_handler = CartPoleHandler()\n",
    "agent = PolicyGradient(env_handler.get_action_space(), env_handler.get_state_space(), model_params)\n",
    "\n",
    "result = train(env_handler, agent, training_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ea026e6-3b96-471f-bee2-9837c871db88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1422\n",
      "Current Benchmark Result:  130.5 Previously:  None . Saving weights...\n",
      "eps:  0.48\n",
      "Flushing buffer...\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1110\n",
      "Agent trained. Yay!\n"
     ]
    }
   ],
   "source": [
    "model_params = ModelHyperParams(\n",
    "    initial_epsilon=0.5,\n",
    "    epsilon_decay_constant=0.7,\n",
    "    gamma=0.5,\n",
    "    no_hidden_layers=2,\n",
    "    units_per_hidden_layer=12,\n",
    "    kernel_initializer=\"he_uniform\"\n",
    ")\n",
    "training_params = TrainingHyperParams(\n",
    "    batch_size=256,\n",
    "    epochs=1000,\n",
    "    steps_per_epoch=2560,\n",
    "    max_buffer_size=256000\n",
    ")\n",
    "\n",
    "env_handler = CartPoleHandler()\n",
    "agent = QLearner(env_handler.get_action_space(), env_handler.get_state_space(), model_params)\n",
    "\n",
    "result = train(env_handler, agent, training_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfd50271-3c46-4179-9838-612f5647a028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1246\n",
      "Current Benchmark Result:  10.0 Previously:  None . Reinitializing...\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1013\n",
      "Current Benchmark Result:  10.0 Previously:  None . Reinitializing...\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.1686\n",
      "Current Benchmark Result:  9.0 Previously:  None . Reinitializing...\n",
      "40/40 [==============================] - 0s 952us/step - loss: 0.0914\n",
      "Current Benchmark Result:  9.0 Previously:  None . Reinitializing...\n",
      "50/50 [==============================] - 0s 850us/step - loss: 0.0730\n",
      "Current Benchmark Result:  10.0 Previously:  None . Reinitializing...\n",
      "60/60 [==============================] - 0s 816us/step - loss: 0.0668\n",
      "Current Benchmark Result:  13.0 Previously:  None . Reinitializing...\n",
      "70/70 [==============================] - 0s 794us/step - loss: 0.1543\n",
      "Current Benchmark Result:  9.0 Previously:  None . Reinitializing...\n",
      "80/80 [==============================] - 0s 758us/step - loss: 0.0501\n",
      "Current Benchmark Result:  9.0 Previously:  None . Reinitializing...\n",
      "90/90 [==============================] - 0s 715us/step - loss: 0.0541\n",
      "Current Benchmark Result:  8.0 Previously:  None . Reinitializing...\n",
      "100/100 [==============================] - 0s 781us/step - loss: 0.0493\n",
      "Current Benchmark Result:  20.0 Previously:  None . Reinitializing...\n",
      "110/110 [==============================] - 0s 703us/step - loss: 0.0668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 09:02:13.108252: W tensorflow/core/data/root_dataset.cc:342] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Benchmark Result:  9.0 Previously:  None . Reinitializing...\n",
      "120/120 [==============================] - 0s 848us/step - loss: 0.0369\n",
      "Current Benchmark Result:  13.0 Previously:  None . Reinitializing...\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0378\n",
      "Current Benchmark Result:  10.0 Previously:  None . Reinitializing...\n",
      "140/140 [==============================] - 0s 803us/step - loss: 0.0428\n",
      "Current Benchmark Result:  10.0 Previously:  None . Reinitializing...\n",
      "150/150 [==============================] - 0s 658us/step - loss: 0.1169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 09:02:26.280507: W tensorflow/core/data/root_dataset.cc:342] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Benchmark Result:  11.0 Previously:  None . Reinitializing...\n",
      "160/160 [==============================] - 0s 683us/step - loss: 0.0599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 09:02:30.135064: W tensorflow/core/data/root_dataset.cc:342] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2024-01-05 09:02:31.204225: W tensorflow/core/data/root_dataset.cc:342] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Benchmark Result:  15.0 Previously:  None . Reinitializing...\n",
      "170/170 [==============================] - 0s 761us/step - loss: 0.0431\n",
      "Current Benchmark Result:  13.0 Previously:  None . Reinitializing...\n",
      "180/180 [==============================] - 0s 682us/step - loss: 0.0490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 09:02:44.526135: W tensorflow/core/data/root_dataset.cc:342] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Benchmark Result:  31.0 Previously:  None . Saving weights...\n",
      "Updating target weights...\n",
      "eps:  0.35\n",
      "Flushing buffer...\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 09:02:45.588382: W tensorflow/core/data/root_dataset.cc:342] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Benchmark Result:  20.0 Previously:  31.0 . Collecting more data...\n",
      "Flushing buffer...\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0241\n",
      "Current Benchmark Result:  20.0 Previously:  31.0 . Collecting more data...\n",
      "Flushing buffer...\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Current Benchmark Result:  31.0 Previously:  31.0 . Collecting more data...\n",
      "Flushing buffer...\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0225\n",
      "Current Benchmark Result:  22.0 Previously:  31.0 . Collecting more data...\n",
      "Flushing buffer...\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0239\n",
      "Current Benchmark Result:  14.0 Previously:  31.0 . Collecting more data...\n",
      "Flushing buffer...\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0240\n",
      "Current Benchmark Result:  30.0 Previously:  31.0 . Collecting more data...\n",
      "Flushing buffer...\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0221\n",
      "Current Benchmark Result:  19.0 Previously:  31.0 . Collecting more data...\n",
      "Flushing buffer...\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0226\n",
      "Current Benchmark Result:  29.0 Previously:  31.0 . Collecting more data...\n",
      "Flushing buffer...\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0220\n",
      "Current Benchmark Result:  28.0 Previously:  31.0 . Collecting more data...\n",
      "Flushing buffer...\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Current Benchmark Result:  18.0 Previously:  31.0 . Collecting more data...\n",
      "Flushing buffer...\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0225\n",
      "Current Benchmark Result:  30.0 Previously:  31.0 . Collecting more data...\n",
      "Flushing buffer...\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0238\n",
      "Current Benchmark Result:  27.0 Previously:  31.0 . Collecting more data...\n",
      "Flushing buffer...\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 09:03:46.735816: W tensorflow/core/data/root_dataset.cc:342] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Benchmark Result:  21.0 Previously:  31.0 . Collecting more data...\n",
      "Flushing buffer...\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 09:03:48.918172: W tensorflow/core/data/root_dataset.cc:342] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m env_handler \u001b[38;5;241m=\u001b[39m CartPoleHandler()\n\u001b[1;32m     19\u001b[0m agent \u001b[38;5;241m=\u001b[39m QLearnerWithTargetNetwork(env_handler\u001b[38;5;241m.\u001b[39mget_action_space(), env_handler\u001b[38;5;241m.\u001b[39mget_state_space(), model_params)\n\u001b[0;32m---> 21\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv_handler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/gymnasium_things/scripts/training.py:34\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(env_handler, agent, training_params)\u001b[0m\n\u001b[1;32m     31\u001b[0m buffer\u001b[38;5;241m.\u001b[39mprepare_experience_for_training(target_builder_fct\u001b[38;5;241m=\u001b[39magent\u001b[38;5;241m.\u001b[39mbuild_targets)\n\u001b[1;32m     32\u001b[0m agent\u001b[38;5;241m.\u001b[39mtrain(buffer\u001b[38;5;241m.\u001b[39mbatch_generator(training_params\u001b[38;5;241m.\u001b[39mbatch_size, agent\u001b[38;5;241m.\u001b[39mgenerator_type))\n\u001b[0;32m---> 34\u001b[0m benchmark \u001b[38;5;241m=\u001b[39m \u001b[43menv_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbenchmark_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m evaluation \u001b[38;5;241m=\u001b[39m env_handler\u001b[38;5;241m.\u001b[39mevaluate_benchmark(prev_benchmark, benchmark)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m evaluation \u001b[38;5;241m==\u001b[39m Evaluation\u001b[38;5;241m.\u001b[39mRESET_MODEL:\n",
      "File \u001b[0;32m/data/gymnasium_things/environment_handler/cart_pole.py:19\u001b[0m, in \u001b[0;36mCartPoleHandler.benchmark_agent\u001b[0;34m(self, agent)\u001b[0m\n\u001b[1;32m     16\u001b[0m counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m finished \u001b[38;5;129;01mand\u001b[39;00m counter \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[0;32m---> 19\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     state, reward, finished, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mperform_action(action)\n\u001b[1;32m     21\u001b[0m     counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/data/gymnasium_things/agents/q_learner.py:15\u001b[0m, in \u001b[0;36mQLearner.get_action\u001b[0;34m(self, state, is_training)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_make_random_action \u001b[38;5;129;01mand\u001b[39;00m is_training:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_random_action()\n\u001b[0;32m---> 15\u001b[0m qs \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_actions\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_actions[np\u001b[38;5;241m.\u001b[39margmax(qs)]\n",
      "File \u001b[0;32m/data/gymnasium_things/agents/q_learner.py:15\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_make_random_action \u001b[38;5;129;01mand\u001b[39;00m is_training:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_random_action()\n\u001b[0;32m---> 15\u001b[0m qs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_actions]\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_actions[np\u001b[38;5;241m.\u001b[39margmax(qs)]\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/keras/src/engine/training.py:2620\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2611\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m   2612\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   2613\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing Model.predict with MultiWorkerMirroredStrategy \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2614\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor TPUStrategy and AutoShardPolicy.FILE might lead to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2617\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   2618\u001b[0m         )\n\u001b[0;32m-> 2620\u001b[0m data_handler \u001b[38;5;241m=\u001b[39m \u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2621\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2622\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2623\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2624\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2625\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2626\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2627\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2628\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2629\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2630\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2631\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2633\u001b[0m \u001b[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[1;32m   2634\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList):\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/keras/src/engine/data_adapter.py:1688\u001b[0m, in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _ClusterCoordinatorExactEvalDataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1687\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1688\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataHandler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/keras/src/engine/data_adapter.py:1292\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute, pss_evaluation_shards)\u001b[0m\n\u001b[1;32m   1289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution \u001b[38;5;241m=\u001b[39m steps_per_execution\n\u001b[1;32m   1291\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m select_data_adapter(x, y)\n\u001b[0;32m-> 1292\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adapter \u001b[38;5;241m=\u001b[39m \u001b[43madapter_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1294\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1298\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistribution_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpss_evaluation_shards\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpss_evaluation_shards\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1306\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1308\u001b[0m strategy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mget_strategy()\n\u001b[1;32m   1310\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/keras/src/engine/data_adapter.py:253\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    242\u001b[0m     x,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    251\u001b[0m ):\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(x, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 253\u001b[0m     x, y, sample_weights \u001b[38;5;241m=\u001b[39m \u001b[43m_process_tensorlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m     sample_weight_modes \u001b[38;5;241m=\u001b[39m broadcast_sample_weight_modes(\n\u001b[1;32m    255\u001b[0m         sample_weights, sample_weight_modes\n\u001b[1;32m    256\u001b[0m     )\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;66;03m# If sample_weights are not specified for an output use 1.0 as weights.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/keras/src/engine/data_adapter.py:1163\u001b[0m, in \u001b[0;36m_process_tensorlike\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m   1160\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _scipy_sparse_to_sparse_tensor(x)\n\u001b[1;32m   1161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m-> 1163\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_convert_single_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mlist_to_tuple(inputs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/util/nest.py:631\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnest.map_structure\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap_structure\u001b[39m(func, \u001b[38;5;241m*\u001b[39mstructure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    547\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[1;32m    548\u001b[0m \n\u001b[1;32m    549\u001b[0m \u001b[38;5;124;03m  Refer to [tf.nest](https://www.tensorflow.org/api_docs/python/tf/nest)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;124;03m    ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnest_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnest_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModality\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCORE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/util/nest_util.py:1066\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(modality, func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[1;32m    970\u001b[0m \n\u001b[1;32m    971\u001b[0m \u001b[38;5;124;03m- For Modality.CORE: Refer to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;124;03m  ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1065\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m Modality\u001b[38;5;241m.\u001b[39mCORE:\n\u001b[0;32m-> 1066\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_tf_core_map_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m Modality\u001b[38;5;241m.\u001b[39mDATA:\n\u001b[1;32m   1068\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _tf_data_map_structure(func, \u001b[38;5;241m*\u001b[39mstructure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/util/nest_util.py:1106\u001b[0m, in \u001b[0;36m_tf_core_map_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m   1101\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (_tf_core_flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m   1102\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _tf_core_pack_sequence_as(\n\u001b[1;32m   1105\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m-> 1106\u001b[0m     \u001b[43m[\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mentries\u001b[49m\u001b[43m]\u001b[49m,\n\u001b[1;32m   1107\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites,\n\u001b[1;32m   1108\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/util/nest_util.py:1106\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1101\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (_tf_core_flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m   1102\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _tf_core_pack_sequence_as(\n\u001b[1;32m   1105\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m-> 1106\u001b[0m     [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m   1107\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites,\n\u001b[1;32m   1108\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/keras/src/engine/data_adapter.py:1158\u001b[0m, in \u001b[0;36m_process_tensorlike.<locals>._convert_single_tensor\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1156\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(x\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, np\u001b[38;5;241m.\u001b[39mfloating):\n\u001b[1;32m   1157\u001b[0m         dtype \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mfloatx()\n\u001b[0;32m-> 1158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1159\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _is_scipy_sparse(x):\n\u001b[1;32m   1160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _scipy_sparse_to_sparse_tensor(x)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1254\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m iterable_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1253\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m replace_iterable_params(args, kwargs, iterable_params)\n\u001b[0;32m-> 1254\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mapi_dispatcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m   1256\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_params = ModelHyperParams(\n",
    "    initial_epsilon=0.5,\n",
    "    epsilon_decay_constant=0.7,\n",
    "    gamma=0.5,\n",
    "    cycles_per_target_update=2,\n",
    "    target_update_fraction=0.5,\n",
    "    no_hidden_layers=2,\n",
    "    units_per_hidden_layer=12,\n",
    "    kernel_initializer=\"he_uniform\"\n",
    ")\n",
    "training_params = TrainingHyperParams(\n",
    "    batch_size=256,\n",
    "    epochs=1000,\n",
    "    steps_per_epoch=2560,\n",
    "    max_buffer_size=256000\n",
    ")\n",
    "\n",
    "env_handler = CartPoleHandler()\n",
    "agent = QLearnerWithTargetNetwork(env_handler.get_action_space(), env_handler.get_state_space(), model_params)\n",
    "\n",
    "result = train(env_handler, agent, training_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5011cf05-f2c6-496f-b2d1-42d38aa7f60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating target weights...\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1068\n",
      "Current Benchmark Result:  9.0 Previously:  None . Reinitializing...\n",
      "Flushing buffer...\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0692\n",
      "Current Benchmark Result:  9.5 Previously:  None . Reinitializing...\n",
      "Flushing buffer...\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0778\n",
      "Current Benchmark Result:  168.5 Previously:  None . Saving weights...\n",
      "Updating target weights...\n",
      "eps:  0.35\n",
      "Flushing buffer...\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0690\n",
      "Current Benchmark Result:  160.5 Previously:  168.5 . Collecting more data...\n",
      "20/20 [==============================] - 0s 990us/step - loss: 0.0643\n",
      "30/30 [==============================] - 0s 904us/step - loss: 0.0598\n",
      "Current Benchmark Result:  156.5 Previously:  168.5 . Collecting more data...\n",
      "40/40 [==============================] - 0s 773us/step - loss: 0.0562\n"
     ]
    }
   ],
   "source": [
    "model_params = ModelHyperParams(\n",
    "    initial_epsilon=0.5,\n",
    "    epsilon_decay_constant=0.7,\n",
    "    gamma=0.5,\n",
    "    cycles_per_target_update=1,\n",
    "    target_update_fraction=0.7,\n",
    "    no_hidden_layers=2,\n",
    "    units_per_hidden_layer=12,\n",
    "    kernel_initializer=\"he_uniform\"\n",
    ")\n",
    "training_params = TrainingHyperParams(\n",
    "    batch_size=256,\n",
    "    epochs=1000,\n",
    "    steps_per_epoch=2560,\n",
    "    max_buffer_size=256000\n",
    ")\n",
    "\n",
    "env_handler = CartPoleHandler()\n",
    "agent = DoubleQLearner(env_handler.get_action_space(), env_handler.get_state_space(), model_params)\n",
    "    \n",
    "result = train(env_handler, agent, training_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2f7ac0-337b-4c81-bc29-54efe0937f07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
